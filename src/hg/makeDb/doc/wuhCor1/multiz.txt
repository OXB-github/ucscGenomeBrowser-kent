#########################################################################
## collecting sequences - (DONE - 2020-03-06 - Hiram)
#########################################################################

mkdir -p /hive/data/genomes/wuhCor1/bed/lastzStrains/sequences

cd /hive/data/genomes/wuhCor1/bed/lastzStrains/sequences

#  The SARS-CoV-2.acc.2020-03-06.list is obtained from Entrez with search term:

#   SARS-CoV-2

# produces 108 sequences as of 06 March

With that list, fetch sequences and gbk records:

mkdir -p fasta gbk
cat SARS-CoV-2.acc.2020-03-06.list | while read acc
do
  if [ ! -s "fasta/${acc}.fa" ]; then
wget -O fasta/${acc}.fa \
   "http://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?db=nuccore&dopt=fasta&sendto=on&id=$acc"
wget -O gbk/${acc}.gbk \
  "http://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?db=nuccore&dopt=gb&sendto=on&id=$acc"
  fi
done

# The coronaviridae.list was obtained from Entrez with the search string:

#  Coronaviridae[Organism] AND srcdb_refseq[PROP] NOT wgs[PROP] NOT cellular organisms[ORGN] NOT AC_000001:AC_999999[PACC] 

#  Which was created from the page:

#  https://www.ncbi.nlm.nih.gov/genomes/GenomesGroup.cgi?taxid=11118

#  when asked to show "RefSeq nucleotides"

# this is a list of 55 sequences, all RefSeq with NC_ identifiers

# With that list, fetch sequences and gbk records:

cat coronaviridae.list | while read acc
do
  if [ ! -s "fasta/${acc}.fa" ]; then
wget -O fasta/${acc}.fa \
   "http://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?db=nuccore&dopt=fasta&sendto=on&id=$acc"
wget -O gbk/${acc}.gbk \
  "http://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?db=nuccore&dopt=gb&sendto=on&id=$acc"
  fi
done

# The china.all.fasta is from: the 'download all sequences' button

#   https://bigd.big.ac.cn/ncov/release_genome

# As well as the listing, from the 'download table' button:

#   china.sequence.list.txt

# Can select the 'complete' sequence list from that table:

 awk -F$'\t' '$5 == "Complete"' 'china.sequence.list.txt' | cut -f1,2,5

# split of the china.all.fasta record:

sed -e 's/^>.* />/;' china.all.fasta > shortNames.china.all.fasta
faSplit byname shortNames.china.all.fasta chinaFasta/

# Now, to eliminate the duplicates from those two sources:

faToTwoBit fasta/*.fa chinaFasta/*.fa t.2bit
twoBitDup t.2bit | awk '{print $1}' | sort > dup.list

# extract the non duplicates
twoBitToFa t.2bit stdout | faSomeRecords -exclude stdin dup.list nonDups.fa

# the duplicates were moved to ncbiDups/ and chinaDups/ directories
# need to ensure our reference is in there, it was a duplicate:
#  NC_045512.2 and MN908947.3 are identical
# and the MN908947.3 sequence was used, move those around to get the
# NC_045512.2 sequence there instead

# some sequences were too short, they were just gene sequences:

twoBitInfo t.2bit stdout | awk '$2 < 25000' > too.small

# LC522350.1      182
# LC523807.1      357
# MN938385.1      287
# MN938387.1      107
# MN970003.1      290
# MT008022.1      322
# MT042773.1      294
# MT050414.1      562
# MT072667.1      670
# MT072668.1      810
# MT081059.1      1260
# MT081066.1      1260
# MT111895.1      770
# MT111896.1      569
# MT127113.1      615
# MT127114.1      1411
# MT127115.1      1269
# MT127116.1      459
# MT152900.1      322
# NM_001371415.1  3339
# NM_021804.3     3596

# moved to ncbiTooSmall/ directory

# Construct UCSC safe sequence names:

mkdir -p safeNameFa

for F in fasta/*.fa chinaFasta/*.fa
do
  B=`basename $F | sed -e "s/\.\([0-9]\+\)/v\1/; s/-/_/g;"`
  printf "%s\n" "${B}"
#  head -12 "${F}" | sed -e 's/^>\([^ ]\+\).*/>\1/;' | sed -e 's/\./v/; s/-/_/g;'
  sed -e 's/^>\([^ ]\+\).*/>\1/;' "${F}" | sed -e 's/\./v/; s/-/_/g;' \
    > safeNameFa/${B}
done

# this leaves 119 sequences, mostly from NCBI, a few from China:

# GWHABKP00000000.fa  MT019532v1.fa   NC_001846v1.fa  NC_018871v1.fa
# GWHABKW00000000.fa  MT019533v1.fa   NC_002306v3.fa  NC_019843v3.fa
# LC521925.fa       MT020781v1.fa   NC_002645v1.fa  NC_022103v1.fa
# LC522972.fa       MT027062v1.fa   NC_003045v1.fa  NC_023760v1.fa
# LC522973.fa       MT027064v1.fa   NC_003436v1.fa  NC_025217v1.fa
# LC522974.fa       MT039873v1.fa   NC_004718v3.fa  NC_026011v1.fa
# LC522975.fa       MT039887v1.fa   NC_005831v2.fa  NC_028752v1.fa
# LC528232v1.fa     MT039888v1.fa   NC_006213v1.fa  NC_028806v1.fa
# LC528233v1.fa     MT039890v1.fa   NC_006577v2.fa  NC_028811v1.fa
# LR757995v1.fa     MT044257v1.fa   NC_009019v1.fa  NC_028814v1.fa
# LR757996v1.fa     MT044258v1.fa   NC_009020v1.fa  NC_028824v1.fa
# LR757997v1.fa     MT049951v1.fa   NC_009021v1.fa  NC_028833v1.fa
# LR757998v1.fa     MT066175v1.fa   NC_009657v1.fa  NC_030292v1.fa
# MN938384v1.fa     MT066176v1.fa   NC_009988v1.fa  NC_030886v1.fa
# MN975262v1.fa     MT072688v1.fa   NC_010437v1.fa  NC_032107v1.fa
# MN985325v1.fa     MT093571v1.fa   NC_010438v1.fa  NC_032730v1.fa
# MN988668v1.fa     MT093631v1.fa   NC_010646v1.fa  NC_034440v1.fa
# MN988713v1.fa     MT106052v1.fa   NC_010800v1.fa  NC_034972v1.fa
# MN994467v1.fa     MT106053v1.fa   NC_011547v1.fa  NC_035191v1.fa
# MN994468v1.fa     MT106054v1.fa   NC_011549v1.fa  NC_038294v1.fa
# MN996527v1.fa     MT118835v1.fa   NC_011550v1.fa  NC_038861v1.fa
# MN996528v1.fa     MT123290v1.fa   NC_012936v1.fa  NC_039207v1.fa
# MN996529v1.fa     MT123291v1.fa   NC_014470v1.fa  NC_039208v1.fa
# MN996530v1.fa     MT123292v1.fa   NC_016991v1.fa  NC_045512v2.fa
# MN996531v1.fa     MT123293v1.fa   NC_016992v1.fa  NMDC60013002_05.fa
# MN997409v1.fa     MT126808v1.fa   NC_016993v1.fa  NMDC60013002_06.fa
# MT007544v1.fa     MT135041v1.fa   NC_016994v1.fa  NMDC60013002_07.fa
# MT019529v1.fa     MT135043v1.fa   NC_016995v1.fa  NMDC60013002_09.fa
# MT019530v1.fa     MT152824v1.fa   NC_016996v1.fa  NMDC60013002_10.fa
# MT019531v1.fa     NC_001451v1.fa  NC_017083v1.fa

# verify no dups:

faToTwoBit safeNameFa/*.fa safeName.2bit
twoBitDup safeName.2bit
# is silent, and sizes are reasonable:
twoBitInfo safeName.2bit stdout | sort -k2,2n | head -2
# NC_039208v1     25425
# NC_035191v1     25995
twoBitInfo safeName.2bit stdout | sort -k2,2n | tail -2
# NC_025217v1     31491
# NC_010646v1     31686

#########################################################################
## kmer calculations for phylo tree generation (DONE - 2020-03-06 - Hiram)
#########################################################################

mkdir /hive/data/genomes/wuhCor1/bed/lastzStrains/kmers
cd /hive/data/genomes/wuhCor1/bed/lastzStrains/kmers

# construct a parasol job list:
ls ../sequences/safeNameFa | sed -e 's/.fa//;' | while read acc
do
  printf "kmerOne %s {check out exists+ kmers/%s/%s.31mers.profile.txt.gz}\n" "${acc}" "${acc}" "${acc}"
done > jobList

### The kmerOne script run in that jobList is:

##############################################
#!/bin/bash

set -beEu -o pipefail

export SORT="$HOME/bin/x86_64/gnusort -S32G --parallel=4 -T /dev/shm"

acc=$1
fa="../sequences/safeNameFa/$acc.fa"

if [ ! -s "kmers/${acc}/${acc}.31mers.profile.txt.gz" ]; then
  mkdir -p "kmers/${acc}"
  ./kmerPrint.pl 31 ${fa} | gzip -c > kmers/${acc}/${acc}.31mers.txt.gz
  zcat kmers/${acc}/${acc}.31mers.txt.gz | cut -f1 | ${SORT} | uniq -c \
     | awk '{printf "%s\t%d\n", $2, $1}' | ${SORT} | gzip -c > kmers/${acc}/${acc}.31mers.profile.txt.gz
  rm -f kmers/${acc}/${acc}.31mers.txt.gz
fi

##############################################

### Takes about 3 minutes to run that parasol job on hgwdev

### After the kmers are done, compare all by all
### Construct a parasol job list to do this with the script:
   
  ~/kent/src/hg/makeDb/doc/wuhCor1/mkCompareJobList.pl > compare.jobList

### That jobList uses the script comparePair
  cp -p ~/kent/src/hg/makeDb/doc/wuhCor1/comparePair ./

### Takes 10 minutes to run on hgwdev:
# Completed: 7021 of 7021 jobs
# CPU time in finished jobs:       1367s      22.78m     0.38h    0.02d  0.000 y
# IO & Wait Time:                 17245s     287.42m     4.79h    0.20d  0.001 y
# Average job time:                   3s       0.04m     0.00h    0.00d
# Longest finished job:               6s       0.10m     0.00h    0.00d
# Submission to last job:           618s      10.30m     0.17h    0.01d

### Collect all the comparisons together into a single file:

find ./compare.31 -type f | xargs cat > allByAll.kmers31.compared.txt

### That is a four column list:
1. target sequence name
2. perCent of target sequence matching to query
3. query sequence name
4. perCent of query sequence matching to target

### The number for 'matching to query' and 'matching to target' is the
### same number:  basesMatched, it is just different denominators:

  $targetPercent = 100.0 * $basesMatched / $targetSize;
   $queryPercent = 100.0 * $basesMatched / $querySize;

### For example:
# LR757996v1      99.7755 MT123290v1      99.6986
# LR757996v1      99.8760 MT106053v1      99.8292
# LR757996v1      99.7755 MN994468v1      99.7253

### Using that four column file, construct an all by all matrix, using
### the matrixUp.pl script:
   ~/kent/src/hg/makeDb/doc/wuhCor1/matrixUp.pl

~/kent/src/hg/makeDb/doc/wuhCor1/matrixUp.pl allByAll.kmers31.compared.txt \
    > data31mer.csv
mv matrixKey.txt matrixKey.31mer.txt

### that matrixKey is the row and column names, the data31mer.csv matrix
### has not column or row header names.

### Now, using the phylip 'neighbor' program to do neighbor joining of that
### matrix into a phylo tree:

mkdir /hive/data/genomes/wuhCor1/bed/lastzStrains/kmers/phylip
cd /hive/data/genomes/wuhCor1/bed/lastzStrains/kmers/phylip

### This 'neighbor' command is very limited, it can only handle 'names'
### that are integers and not longer that 10 digits.  The names are
### shortened by the mkTestData.pl script:

  ~/kent/src/hg/makeDb/doc/wuhCor1/mkTestData.pl

### I realize now, that script is overly complicated, it should simply assign
### sequence integers to each name and output the correspondence table rather
### than trying to shorten the names magically.  Way too much work.
### Done the hard way:

   ~/kent/src/hg/makeDb/doc/wuhCor1/mkTestData.pl 31 > infile \
       2> name.31mer.translate.txt

### The 'neighbor' command is an interactive command, it expects to
### find the input file: 'infile' which was just made by mkTestData.pl
### it displays an interactive menu, use the 'N' selection command to select
### UPGMA type of joining, see also additional comments of how this was run
### in ../staAur2/multiz369way.txt

### After neighbor is done, rename the results, and restore
the sequence names in the final upgma.31mer.nh tree:

if [ -s outfile ]; then
  rm -f outfile.31mer
  mv outfile outfile.31mer
fi

if [ -s outtree ]; then
  rm -f outfile.31mer outtree.31mer
  mv outtree outtree.31mer
fi

# Note the duplicate sequence MN908947v3 was used instead of NC_045512v2
# fixup the name with the sed

cat outtree.31mer \
  | sed -e 's/(/(\n/g; s/,/,\n/g; s/)/\n)/g; s/ //g;' \
  | grep -v "^$" | ~/kent/src/hg/utils/phyloTrees/binaryTree.pl \
    -nameTranslate=name.31mer.translate.txt -noInternal -lineOutput /dev/stdin \
      | sed -e 's/MN908947v3/NC_045512v2/;' > upgma.31mer.nh

# Using the TreeGraph editor on the Mac, rework the tree to get the
# reference NC_045512v2 at the top of the tree, this makes the tree:

    ~/kent/src/hg/makeDb/doc/wuhCor1/wuhCor1.119way.nh

#########################################################################
## setting up multiz

mkdir /hive/data/genomes/wuhCor1/bed/multiz119way
cd /hive/data/genomes/wuhCor1/bed/multiz119way

    # create species list and stripped down tree for autoMZ
    sed 's/[a-z][a-z]*_//g; s/:[0-9\.][0-9\.]*//g; s/;//; /^ *$/d' \
       ../../goldenPath/multiz119way/sequenceNames.119way.nh \
	| xargs echo | sed 's/ //g; s/,/ /g' > tree.nh

    sed 's/[()]//g; s/,/ /g' tree.nh > species.list

    # all the nets are the same, can use ordinary mafNet:
    #	bash shell syntax here ...
    cd /hive/data/genomes/wuhCor1/bed/multiz119way
    export H=/hive/data/genomes/wuhCor1/bed
    mkdir mafLinks
    # the grep -v NC_045512v2 eliminates the self alignment
    ls -d ../lastzStrains/runDir/lastz.* | grep -v NC_045512v2 | while read D
do
  if [ -d "${D}" ]; then
    asmId=`basename $D | sed -e 's/lastz.//;'`
    mafNet="${D}/mafNet/NC_045512v2.maf.gz"
    if [ ! -f "${mafNet}" ]; then
      echo "ERROR: can not find mafNet file ${mafNet}" 1>&2
      exit 255
    fi
    echo ln -s ../$mafNet mafLinks/NC_045512v2.$asmId.maf.gz
    ln -s ../$mafNet mafLinks/NC_045512v2.$asmId.maf.gz
  fi
done


    # verify the symLinks are good:
    ls -ogrtL mafLinks/* | sed -e 's/^/# /; s/-rw-rw-r-- 1//;' | head -4
#  17193 Mar  9 17:09 mafLinks/NC_045512v2.GWHABKP00000000.maf.gz
#  12617 Mar  9 17:17 mafLinks/NC_045512v2.NC_038294v1.maf.gz
#  11529 Mar  9 17:17 mafLinks/NC_045512v2.NC_012936v1.maf.gz
#  12046 Mar  9 17:20 mafLinks/NC_045512v2.NC_034440v1.maf.gz

    ls -ogrtL mafLinks/* | sed -e 's/^/# /; s/-rw-rw-r-- 1//;' | tail -4
#  11733 Mar  9 17:38 mafLinks/NC_045512v2.NC_017083v1.maf.gz
#   8549 Mar  9 17:38 mafLinks/NC_045512v2.NC_016991v1.maf.gz
#  13176 Mar  9 17:38 mafLinks/NC_045512v2.MT039888v1.maf.gz
#  13143 Mar  9 17:39 mafLinks/NC_045512v2.NMDC60013002_06.maf.gz

# leaves 118 files:
    ls -ogrtL mafLinks/*.maf.gz | wc -l
# 118

    # scan the names to verify sanity:
    zcat mafLinks/*.maf.gz | grep "^s " | awk '{print $2}' | sort \
   | uniq -c | sort -rn | sed -e 's/^/# /;' | less
# should look like:
#     775 NC_045512v2.NC_045512v2
#      22 NC_025217v1.NC_025217v1
#      22 LR757997v1.LR757997v1
#      21 NC_016991v1.NC_016991v1
#      21 GWHABKW00000000.GWHABKW00000000
#      18 NC_012936v1.NC_012936v1
#     ...
#       1 LC528232v1.LC528232v1
#       1 LC522975.LC522975
#       1 LC522974.LC522974
#       1 LC522973.LC522973
#       1 LC522972.LC522972
#       1 LC521925.LC521925
#       1 GWHABKP00000000.GWHABKP00000000


    ssh ku
    cd /hive/data/genomes/wuhCor1/bed/multiz119way
    mkdir run maf
    cd run
    mkdir penn
    cp -p /cluster/bin/penn/multiz.2009-01-21_patched/multiz penn
    cp -p /cluster/bin/penn/multiz.2009-01-21_patched/maf_project penn
    cp -p /cluster/bin/penn/multiz.2009-01-21_patched/autoMZ penn

    ls ../mafLinks | sed -e 's/.maf.gz//; s/NC_045512v2.//' > maf.list

cat << '_EOF_' > template
    printf '#LOOP
./autoMultiz.csh $(file1) {check out line+ /hive/data/genomes/wuhCor1/bed/multiz119way/maf/$(root1).maf}
#ENDLOOP
' > template

    printf '#!/bin/csh -ef
set db = NC_045512v2
set c = $1
set result = $2
set run = `/bin/pwd`
set tmp = /dev/shm/$db/multiz.$c
set pairs = /hive/data/genomes/wuhCor1/bed/multiz119way/mafLinks
/bin/rm -fr $tmp
/bin/mkdir -p $tmp
/bin/cp -p ../tree.nh ../species.list $tmp
pushd $tmp > /dev/null
foreach s (`/bin/sed -e "s/$db //;" species.list`)
    set in = $pairs/$db.$s.maf
    set out = $db.$s.sing.maf
    if (-e $in.gz) then
        /bin/zcat $in.gz > $out
        if (! -s $out) then
            echo "##maf version=1 scoring=autoMZ" > $out
        endif
    else if (-e $in) then
        /bin/ln -s $in $out
    else
        echo "##maf version=1 scoring=autoMZ" > $out
    endif
end
set path = ($run/penn $path); rehash
$run/penn/autoMZ + T=$tmp E=$db "`cat tree.nh`" $db.*.sing.maf $c \
        > /dev/null
popd > /dev/null
/bin/rm -f $result.maf
/bin/cp -p $tmp/$c $result.maf
/bin/rm -fr $tmp
' > autoMultiz.csh

    gensub2 maf.list single template jobList
    para create jobList
    para try ... check ... push
    para time
# Completed: 118 of 118 jobs
# CPU time in finished jobs:      61696s    1028.27m    17.14h    0.71d  0.002 y
# IO & Wait Time:                   338s       5.63m     0.09h    0.00d  0.000 y
# Average job time:                 526s       8.76m     0.15h    0.01d
# Longest finished job:             555s       9.25m     0.15h    0.01d
# Submission to last job:           580s       9.67m     0.16h    0.01d

# put the results back together into a single file, and fixup the s line names
# the first sed is duplicating the sequence name on the s lines, transforming
# from:
# s MN996528v1      0 1 + 29891 A
# to
# s MN996528v1.MN996528v1      0 1 + 29891 A
# and the ones that belong to the reference:
# s NC_045512v2     0 1 + 29903 A
# become via the second sed:
# s wuhCor1.NC_045512v2

cd /hive/data/genomes/wuhCor1/bed/multiz119way
head -1 maf/NC_018871v1.maf > multiz119way.maf
for F in maf/*.maf
do
    echo "${F}" 1>&2
    egrep -v "^#" ${F} | sed -e 's#^s \([A-Z0-9a-z_]*\)#s \1.\1#;'
done | sed -e 's#^s NC_045512v2.NC_045512v2#s wuhCor1.NC_045512v2#;' \
>> multiz119way.maf
tail -1 maf/NC_018871v1.maf >> multiz119way.maf

# -rw-rw-r-- 1 950715307 Mar  9 22:34 multiz119way.maf

# scan names to verify sanity:
grep "^s " multiz119way.maf | awk '{print $2}' | sort | uniq -c \
  | sort -rn | sed -e 's/^/# /;' | less
#  132042 wuhCor1.NC_045512v2
#  132042 MT135043v1.MT135043v1
#  132042 MT135041v1.MT135041v1
#  132042 MT049951v1.MT049951v1
#  132042 MT039890v1.MT039890v1
#  132042 MT007544v1.MT007544v1
#  131570 MT019531v1.MT019531v1
...
#   37288 NC_011547v1.NC_011547v1
#   33630 NC_016992v1.NC_016992v1
#   28202 NC_016993v1.NC_016993v1
#   25724 NC_039208v1.NC_039208v1

    # Load into database
    ssh hgwdev
    cd /hive/data/genomes/wuhCor1/bed/multiz119way
    mkdir /gbdb/wuhCor1/multiz119way
    ln -s `pwd`/multiz119way.maf /gbdb/wuhCor1/multiz119way
    cd /dev/shm
    time hgLoadMaf wuhCor1 multiz119way
# Loaded 132042 mafs in 1 files from /gbdb/wuhCor1/multiz119way
# real    0m6.780s

    # merge that into a single block:
    cd /hive/data/genomes/wuhCor1/bed/multiz119way

    time mafFrag wuhCor1 multiz119way NC_045512v2 0 29903 + mafFrag.multiz119way.maf
    # real    0m12.119s

    printf '#!/usr/bin/env perl

use strict;
use warnings;

my $file = shift;

open (FH, "<$file") or die "can not read $file";
while (my $line = <FH>) {
  if ($line =~ m/^s /) {
    chomp $line;
    my @a = split("\s+", $line);
    if (scalar(@a) == 7) {
      if ($a[1] !~ m/wuhCor1/) {
        $a[1] = "$a[1].$a[1]";
      }
      $a[6] =~ s/\./-/g;
      print join(" ", @a), "\n";
    } else {
      die "ERROR: s line found not 7 fields ?";
    } 
  } else {
    printf "%s", $line;
  }
}
close (FH);
' > dotToDash.pl

chmod +x dotToDash.pl

./dotToDash.pl mafFrag.multiz119way.maf > defraged.multiz119way.maf

# and reload:
rm /gbdb/wuhCor1/multiz119way/multiz119way.maf
ln -s `pwd`/defraged.multiz119way.maf \
   /gbdb/wuhCor1/multiz119way/multiz119way.maf

cd /dev/shm
time hgLoadMaf wuhCor1 multiz119way
# Loaded 1 mafs in 1 files from /gbdb/wuhCor1/multiz119way
# real    0m0.056s

# construct strain-name track

cat defraged.multiz119way.maf \
 | sed -f ~/kent/src/hg/makeDb/doc/wuhCor1/ucscName.strainName.sed \
  | sed -e 's/wuhCor1.G3686v1_2014/wuhCor1.KM034562v1/' \
    > strainName.multiz119way.maf

mkdir /gbdb/wuhCor1/strainName119way
rm /gbdb/wuhCor1/strainName119way/strainName119way.maf
ln -s `pwd`/strainName.multiz119way.maf \
   /gbdb/wuhCor1/strainName119way/strainName119way.maf

cd /dev/shm
time hgLoadMaf wuhCor1 strainName119way

    time hgLoadMafSummary -verbose=2 -minSize=30000 \
	-mergeGap=1500 -maxSize=200000 wuhCor1 multiz119waySummary \
	/gbdb/wuhCor1/multiz119way/multiz119way.maf
# Created 1343139 summary blocks from 20786747 components and 4609310 mafs from /gbdb/wuhCor1/multiz119way/multiz119way.maf
# real    0m50.372s

# -rw-rw-r--   1  225415432 Mar  9 11:58 multiz119way.tab
# -rw-rw-r--   1   60694329 Mar  9 12:01 multiz119waySummary.tab

    wc -l multiz119way*.tab
#  4609310 multiz119way.tab
#  1343139 multiz119waySummary.tab

    rm multiz119way*.tab

##############################################################################
# frames 2020-03-09 - Hiram first attempt, one gene track used
genePredSingleCover ../ncbiGene/wuhCor1.ncbiGene.ucsc.genePred.gz stdout \
  | genePredToMafFrames wuhCor1 mafFrag.multiz119way.maf \
     frames.tab wuhCor1 /dev/stdin

hgLoadMafFrames wuhCor1 multiz119wayFrames frames.tab  

##############################################################################
# GAP ANNOTATE multiz119way MAF AND LOAD TABLES (DONE - 2020-03-09 - Hiram)
    # mafAddIRows has to be run on single chromosome maf files, it does not
    #	function correctly when more than one reference sequence
    #	are in a single file.  Need to split of the maf file into individual
    #   maf files
    mkdir -p /hive/data/genomes/wuhCor1/bed/multiz119way/anno/mafSplit
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/anno/mafSplit

    time mafSplit -outDirDepth=2 -byTarget -useFullSequenceName \
        /dev/null . ../../multiz119way.maf
    #   real    0m43.493s

    find . -type f | wc -l
    #   1012

    # check for N.bed files everywhere:
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/anno
    for DB in `cat ../species.list`
do
    if [ ! -s /hive/data/genomes/${DB}/${DB}.N.bed ]; then
        echo "MISS: ${DB}"
#         cd /hive/data/genomes/${DB}
#         twoBitInfo -nBed ${DB}.2bit ${DB}.N.bed
    else
        echo "  OK: ${DB}"
    fi
done

    cd /hive/data/genomes/wuhCor1/bed/multiz119way/anno
    for DB in `cat ../species.list`
do
    echo "${DB} "
    ln -s  /hive/data/genomes/${DB}/${DB}.N.bed ${DB}.bed
    echo ${DB}.bed  >> nBeds
    ln -s  /hive/data/genomes/${DB}/chrom.sizes ${DB}.len
    echo ${DB}.len  >> sizes
done
    # make sure they all are successful symLinks:
    ls -ogrtL

    screen -S gapAnno      # use a screen to control this longish job
    ssh ku
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/anno
    mkdir result
    # there was a stray 'result/mafSplit' directory ending up in this, avoid
    # it via the grep -v mafSplit
    find ./mafSplit -type d | sed -e 's#./mafSplit/##' | grep -v mafSplit \
       | while read D
do
    echo mkdir -p result/${D}
    mkdir -p result/${D}
done
    printf '#LOOP
mafAddIRows -nBeds=nBeds mafSplit/$(path1) /hive/data/genomes/wuhCor1/wuhCor1.2bit {check out exists+ result/$(path1)}
#ENDLOOP
' > template

    find ./mafSplit -type f | sed -e 's#^./mafSplit/##' > maf.list
    gensub2 maf.list single template jobList
    # limit jobs on a node with the ram=32g requirement because they go fast
    para -ram=32g create jobList
    para try ... check ... push ...
# Completed: 1012 of 1012 jobs
# CPU time in finished jobs:        427s       7.12m     0.12h    0.00d  0.000 y
# IO & Wait Time:                  2676s      44.59m     0.74h    0.03d  0.000 y
# Average job time:                   3s       0.05m     0.00h    0.00d
# Longest finished job:              14s       0.23m     0.00h    0.00d
# Submission to last job:           112s       1.87m     0.03h    0.00d

    # verify all result files have some content, look for 0 size files:
    find ./result -type f -size 0
    # should see none
    # or in this manner:
    find ./result -type f | xargs ls -og | sort -k3nr | tail

    # combine into one file  (the 1>&2 redirect sends the echo to stderr)
    head -q -n 1 result/0/2/chrUn_KN149893v1.maf > wuhCor1.119way.maf
    time find ./result -type f | while read F
do
    echo "${F}" 1>&2
    grep -h -v "^#" ${F}
done >> wuhCor1.119way.maf
    # real    1m22.625s

    #	these maf files do not have the end marker, this does nothing:
    #	tail -q -n 1 result/0/2/chrUn_KN149893v1.maf >> wuhCor1.119way.maf
    # How about an official end marker:
    echo "##eof maf" >> wuhCor1.119way.maf
    ls -og
# -rw-rw-r--  1 5791972643 Mar  9 12:13 wuhCor1.119way.maf

    du -hsc wuhCor1.119way.maf ../*.maf
    # 5.4G    wuhCor1.119way.maf
    # 2.8G    ../multiz119way.maf

    # construct symlinks to get the individual maf files into gbdb:
    rm /gbdb/wuhCor1/multiz119way/multiz119way.maf   # remove previous results
    ln -s `pwd`/wuhCor1.119way.maf /gbdb/wuhCor1/multiz119way/multiz119way.maf

    # Load into database
    cd /dev/shm
    time hgLoadMaf -pathPrefix=/gbdb/wuhCor1/multiz119way wuhCor1 multiz119way
    # Loaded 4981463 mafs in 1 files from /gbdb/wuhCor1/multiz119way
    # real    1m4.890s

    time hgLoadMafSummary -verbose=2 -minSize=30000 \
	-mergeGap=1500 -maxSize=200000 wuhCor1 multiz119waySummary \
        /gbdb/wuhCor1/multiz119way/multiz119way.maf
# Created 1343139 summary blocks from 20786747 components and 4981463 mafs from /gbdb/wuhCor1/multiz119way/multiz119way.maf
# real    0m59.393s

# -rw-rw-r--   1  244520097 Mar  9 12:14 multiz119way.tab
# -rw-rw-r--   1   63380607 Mar  9 12:18 multiz119waySummary.tab

    rm multiz119way*.tab

######################################################################
# multiz119way MAF FRAMES (DONE - 2020-03-09 - Hiram)
    ssh hgwdev
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/frames
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/frames
#   survey all the genomes to find out what kinds of gene tracks they have
    printf '#!/bin/csh -fe
foreach db (`cat ../species.list`)
    printf "# ${db}: "
    set tables = `hgsql $db -N -e "show tables" | egrep "Gene|ncbiRefSeq"`
    foreach table ($tables)
        if ($table == "ensGene" || $table == "refGene" || \
           $table == "ncbiRefSeq" || $table == "mgcGenes" || \
           $table == "knownGene" || $table == "xenoRefGene" ) then
           set count = `hgsql $db -N -e "select count(*) from $table"`
            echo -n "${table}: ${count}, "
        endif
    end
    set orgName = `hgsql hgcentraltest -N -e \
            "select scientificName from dbDb where name='"'"'$db'"'"'"`
    set orgId = `hgsql hgFixed -N -e \
            "select id from organism where name='"'"'$orgName'"'"'"`
    if ($orgId == "") then
        echo "Mrnas: 0"
    else
        set count = `hgsql hgFixed -N -e "select count(*) from gbCdnaInfo where organism=$orgId"`
        echo "Mrnas: ${count}"
    endif
end
' > showGenes.csh

    chmod +x ./showGenes.csh
    time ./showGenes.csh
# wuhCor1: ensGene: 62895, mgcGenes: 16938, ncbiRefSeq: 56101, refGene: 16812, xenoRefGene: 136995, Mrnas: 1535827
# gasAcu1: ensGene: 29245, refGene: 65, xenoRefGene: 291425, Mrnas: 280208
# oryLat2: ensGene: 25434, refGene: 903, xenoRefGene: 262904, Mrnas: 669014
# tetNig2: ensGene: 24078, xenoRefGene: 252452, Mrnas: 100127
# fr3: ensGene: 29241, ncbiRefSeq: 33131, refGene: 655, Mrnas: 335149
# lepOcu1: ensGene: 27887, Mrnas: 87
# hg38: ensGene: 208239, knownGene: 247541, mgcGenes: 36638, ncbiRefSeq: 166923, refGene: 85561, xenoRefGene: 198240, Mrnas: 11716560
# mm10: ensGene: 103734, knownGene: 142446, mgcGenes: 27606, ncbiRefSeq: 106520, refGene: 44703, xenoRefGene: 190199, Mrnas: 5493887
# galGal6: ensGene: 39288, ncbiRefSeq: 62183, refGene: 7482, xenoRefGene: 149238, Mrnas: 639553
# xenTro9: ensGene: 56323, ncbiRefSeq: 43724, refGene: 8806, xenoRefGene: 161423, Mrnas: 1298807
# latCha1: ensGene: 26660, ncbiRefSeq: 40763, xenoRefGene: 427419, Mrnas: 86
# calMil1: ensGene: 49990, ncbiRefSeq: 30682, xenoRefGene: 401231, Mrnas: 146276

real    1m57.753s

    # use knownGene for hg38 and mm10
    # everything else use ensGene
 
    mkdir genes

    #   1. knownGene: hg38 and mm10
    for DB in hg38 mm10
    do
      hgsql -N -e "select name,chrom,strand,txStart,txEnd,cdsStart,cdsEnd,exonCount,exonStarts,exonEnds from knownGene" ${DB} \
        | genePredSingleCover stdin stdout | gzip -2c \
          > genes/${DB}.gp.gz
      printf "#  ${DB}: "
      genePredCheck -db=${DB} genes/${DB}.gp.gz
    done
#  hg38: checked: 22100 failed: 0
#  mm10: checked: 22026 failed: 0

    #   2. ensGene: wuhCor1 gasAcu1 oryLat2 tetNig2 fr3 lepOcu1
    #               galGal6 xenTro9 latCha1 calMil1
    for DB in wuhCor1 gasAcu1 oryLat2 tetNig2 fr3 lepOcu1 galGal6 xenTro9 latCha1 calMil1
do
hgsql -N -e "select name,chrom,strand,txStart,txEnd,cdsStart,cdsEnd,exonCount,exonStarts,exonEnds
from ensGene" ${DB} \
      | genePredSingleCover stdin stdout | gzip -2c \
        > /dev/shm/${DB}.tmp.gz
    mv /dev/shm/${DB}.tmp.gz genes/$DB.gp.gz
    printf "# ${DB}: "
    genePredCheck -db=${DB} genes/${DB}.gp.gz
done
# wuhCor1: checked: 25259 failed: 0
# gasAcu1: checked: 20631 failed: 0
# oryLat2: checked: 19586 failed: 0
# tetNig2: checked: 19539 failed: 0
# fr3: checked: 20017 failed: 0
# lepOcu1: checked: 18252 failed: 0
# galGal6: checked: 16651 failed: 0
# xenTro9: checked: 19819 failed: 0
# latCha1: checked: 19539 failed: 0
# calMil1: checked: 19188 failed: 0

    # verify counts for genes are reasonable:
    for T in genes/*.gz
do
    echo -n "# $T: "
    zcat $T | cut -f1 | sort | uniq -c | wc -l
done
# genes/calMil1.gp.gz: 19188
# genes/wuhCor1.gp.gz: 25259
# genes/fr3.gp.gz: 20017
# genes/galGal6.gp.gz: 16651
# genes/gasAcu1.gp.gz: 20631
# genes/hg38.gp.gz: 22082
# genes/latCha1.gp.gz: 19539
# genes/lepOcu1.gp.gz: 18252
# genes/mm10.gp.gz: 22026
# genes/oryLat2.gp.gz: 19586
# genes/tetNig2.gp.gz: 19539
# genes/xenTro9.gp.gz: 19819

    time (cat ../anno/wuhCor1.119way.maf \
	| genePredToMafFrames wuhCor1 stdin stdout \
          `cat ../species.list.txt | xargs echo \
            | sed -e "s#\([a-zA-Z0-9]*\)#\1 genes/\1.gp.gz#g;"` \
		| gzip > multiz119wayFrames.bed.gz)
    # real    1m29.321s

    # verify there are frames on everything, should be 4 species:
    zcat multiz119wayFrames.bed.gz | awk '{print $4}' | sort | uniq -c \
       | sed -e 's/^/# /;'
#  421479 calMil1
#  235622 wuhCor1
#  413788 fr3
#  451258 galGal6
#  420945 gasAcu1
#  415541 hg38
#  432488 latCha1
#  460409 lepOcu1
#  426202 mm10
#  401711 oryLat2
#  383412 tetNig2
#  433380 xenTro9

    #   load the resulting file
    ssh hgwdev
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/frames
    time hgLoadMafFrames wuhCor1 multiz119wayFrames multiz119wayFrames.bed.gz
    #   real    0m10.853s

    time featureBits -countGaps wuhCor1 multiz119wayFrames
    # 54994220 bases of 1371719383 (4.009%) in intersection
    # real    0m23.424s

    #   enable the trackDb entries:
# frames multiz119wayFrames
# irows on
    #   appears to work OK

#########################################################################
# Phylogenetic tree from 119way (DONE - 2020-03-09 - Hiram)
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/4d
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/4d

    # using the ensGene
    hgsql -N -e "select name,chrom,strand,txStart,txEnd,cdsStart,cdsEnd,exonCount,exonStarts,exonEnds from refGene" wuhCor1 \
      | genePredSingleCover stdin stdout > wuhCor1.ensGeneNR.gp
    genePredCheck -db=wuhCor1 wuhCor1.ensGeneNR.gp
    # checked: 14875 failed: 0

    # the annotated maf is:
    og ../anno/wuhCor1.119way.maf
# -rw-rw-r-- 1 5791972643 Mar  9 12:13 ../anno/wuhCor1.119way.maf

    mkdir annoSplit
    cd annoSplit
    time mafSplit -verbose=2 -outDirDepth=2 -byTarget -useFullSequenceName \
	/dev/null . ../../anno/wuhCor1.119way.maf
    # real    1m30.335s

    find . -type f | wc -l
    #   1012
    ssh ku
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/4d/run
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/4d/run
    mkdir ../mfa

    # newer versions of msa_view have a slightly different operation
    # the sed of the gp file inserts the reference species in the chr name
    cat << '_EOF_' > 4d.csh
#!/bin/csh -fex
set PHASTBIN = /cluster/bin/phast.build/cornellCVS/phast.2010-12-30/bin
set GP = wuhCor1.ensGeneNR.gp

set r = "/hive/data/genomes/wuhCor1/bed/multiz119way"
set c = $1
set infile = $r/4d/$2
set outDir = $r/4d/$3
set outfile = $r/4d/run/$4
/bin/mkdir -p $outDir
cd /dev/shm
/bin/awk -v C=$c '$2 == C {print}' $r/4d/$GP | sed -e "s/\t$c\t/\twuhCor1.$c\t/" > $c.gp
set NL=`wc -l $c.gp| gawk '{print $1}'`
echo $NL
if ("$NL" != "0") then
    $PHASTBIN/msa_view --4d --features $c.gp -i MAF $infile -o SS > $c.ss
    $PHASTBIN/msa_view -i SS --tuple-size 1 $c.ss > $outfile
else
    echo "" > $outfile
endif
/bin/rm -f /dev/shm/$c.gp /dev/shm/$c.ss
_EOF_
#########################################
    chmod +x 4d.csh

    find ../annoSplit -type f | sed -e "s#../annoSplit/##" > maf.list
    wc -l maf.list
# 1012 maf.list

    printf '#LOOP
4d.csh $(root1) annoSplit/$(dir1)/$(file1) mfa/$(dir1) {check out line+ ../mfa/$(dir1)/$(root1).mfa}
#ENDLOOP
' > template

    mkdir ../mfa
    gensub2 maf.list single template jobList
    para create jobList
    para try ... check
    para time
# Completed: 1012 of 1012 jobs
# CPU time in finished jobs:        406s       6.77m     0.11h    0.00d  0.000 y
# IO & Wait Time:                  2465s      41.08m     0.68h    0.03d  0.000 y
# Average job time:                   3s       0.05m     0.00h    0.00d
# Longest finished job:              21s       0.35m     0.01h    0.00d
# Submission to last job:           107s       1.78m     0.03h    0.00d

    # Not all results have contents, or finish successfully, that is OK
    # it is because not all contigs have genes, only gene sequences are measured

    # combine mfa files
    ssh hgwdev
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/4d
    # remove the broken empty files, size 0 and size 1:
    find ./mfa -type f -size 0 | xargs rm -f
    # sometimes this doesn't work, don't know why, it isn't safe, it
    # outputs files that are larger than size 1:
    ### XXX find ./mfa -type f -size 1 | xargs rm -f
    # when it doesn't, use this empty list procedure
    find ./mfa -type f | xargs ls -og | awk '$3 < 2' | awk '{print $NF}' \
        > empty.list
    cat empty.list | xargs rm -f
    # see what is left:
    ls -ogrt mfa/*/*/*.mfa | sort -k3nr | wc
    #             140     980    8396

    # want comma-less species.list
    time /cluster/bin/phast.build/cornellCVS/phast.2010-12-30/bin/msa_view \
	--aggregate "`cat ../species.list`" mfa/*/*/*.mfa | sed s/"> "/">"/ \
	    > 4d.all.mfa
    # real    0m1.369s

    # check they are all in there:
    grep "^>" 4d.all.mfa | sed -e 's/^/# /;'
# >wuhCor1
# >gasAcu1
# >oryLat2
# >tetNig2
# >fr3
# >lepOcu1
# >hg38
# >mm10
# >galGal6
# >xenTro9
# >latCha1
# >calMil1

    sed 's/[a-z][a-z]*_//g; s/:[0-9\.][0-9\.]*//g; s/;//; /^ *$/d' \
	../wuhCor1.119way.nh | xargs echo | sed -e 's/ //g' > tree_commas.nh
    # tree_commas.nh looks like:
    # ((((wuhCor1,(gasAcu1,(oryLat2,(tetNig2,fr3)))),lepOcu1),((((hg38,mm10),galGal6),xenTro9),latCha1)),calMil1)


    # use phyloFit to create tree model (output is phyloFit.mod)
    time /cluster/bin/phast.build/cornellCVS/phast.2010-12-30/bin/phyloFit \
	    --EM --precision MED --msa-format FASTA --subst-mod REV \
		--tree tree_commas.nh 4d.all.mfa
    #  real    7m11.213s

    mv phyloFit.mod all.mod

    grep TREE all.mod
# TREE: ((((wuhCor1:0.611884,(gasAcu1:0.328166,(oryLat2:0.456031,
# (tetNig2:0.205925,fr3:0.188605):0.228366):0.00373574):0.355398):0.157683,
# lepOcu1:0.563099):0.19044,((((hg38:0.183526,mm10:0.265304):0.337095,
# galGal6:0.450474):0.106427,xenTro9:0.776415):0.0616915,
# latCha1:0.561233):0.0520656):0.328637,calMil1:0.328637);


    # compare these calculated lengths to the tree extracted from 191way:
    grep TREE all.mod | sed -e 's/TREE: //' \
       | /cluster/bin/phast/all_dists /dev/stdin | grep wuhCor1 \
          | sed -e "s/wuhCor1.//;"  | sort > new.dists
    /cluster/bin/phast/all_dists ../wuhCor1.119way.nh | grep wuhCor1 \
        | sed -e "s/wuhCor1.//;" | sort > old.dists
     # printing out the 'new', the 'old' the 'difference' and percent difference
    join new.dists old.dists | awk '{
  printf "#\t%s\t%8.5f\t%8.5f\t%8.5f\t%8.5f\n", $1, $2, $3, $2-$3, 100*($2-$3)/$3 }' \
      | sort -k3n
#       gasAcu1  1.29545         1.24781         0.04764         3.81814
#       lepOcu1  1.33267         1.27438         0.05828         4.57335
#       fr3      1.38799         1.41542        -0.02743        -1.93794
#       tetNig2  1.40531         1.33573         0.06958         5.20898
#       oryLat2  1.42705         1.49836        -0.07131        -4.75940
#       latCha1  1.57331         2.29037        -0.71706        -31.30778
#       calMil1  1.61728         2.05107        -0.43379        -21.14948
#       galGal6  1.63067         2.02187        -0.39120        -19.34859
#       hg38     1.70081         2.06849        -0.36768        -17.77507
#       mm10     1.78259         2.27906        -0.49647        -21.78405
#       xenTro9  1.85018         1.76037         0.08981         5.10171

#########################################################################
# phastCons 119way (TBD - 2016-06-06 - Hiram)
    # split 119way mafs into 10M chunks and generate sufficient statistics
    # files for # phastCons
    ssh ku
    mkdir -p /hive/data/genomes/wuhCor1/bed/multiz119way/cons/SS
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/cons/SS
    mkdir result done

    printf '#!/bin/csh -ef
set d = $1
set c = $2
set doneDir = done/$d
set MAF = /hive/data/genomes/wuhCor1/bed/multiz119way/anno/result/$d/$c.maf
set WINDOWS = /hive/data/genomes/wuhCor1/bed/multiz119way/cons/SS/result/$d/$c
set WC = `cat $MAF | wc -l`
set NL = `grep "^#" $MAF | wc -l`
if ( -s $3 ) then
    exit 0
endif
if ( -s $3.running ) then
    exit 0
endif

/bin/mkdir -p $doneDir
/bin/date >> $3.running

/bin/rm -fr $WINDOWS
/bin/mkdir -p $WINDOWS
pushd $WINDOWS > /dev/null
if ( $WC != $NL ) then
/cluster/bin/phast.build/cornellCVS/phast.2010-12-30/bin/msa_split \\
    $MAF -i MAF -o SS -r $WINDOWS/$c -w 10000000,0 -I 1000 -B 5000
endif
popd > /dev/null
/bin/date >> $3
/bin/rm -f $3.running
' > mkSS.csh

    chmod +x mkSS.csh

    printf '#LOOP
mkSS.csh $(dir1) $(root1) {check out line+ done/$(dir1)/$(root1)}
#ENDLOOP
' > template

    find ../../anno/result -type f | sed -e "s#../../anno/result/##" > maf.list
    wc -l maf.list
# 1012 maf.list

    ssh ku
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/cons/SS

    gensub2 maf.list single template jobList
    # beware overwhelming the cluster with these quick high I/O jobs
    para create jobList
    para try ... check ... etc
    para -maxJob=64 push
# Completed: 1012 of 1012 jobs
# CPU time in finished jobs:        752s      12.53m     0.21h    0.01d  0.000 y
# IO & Wait Time:                  2558s      42.64m     0.71h    0.03d  0.000 y
# Average job time:                   3s       0.05m     0.00h    0.00d
# Longest finished job:              50s       0.83m     0.01h    0.00d
# Submission to last job:            78s       1.30m     0.02h    0.00d

    find ./result -type f | wc -l
    # 988

    # Run phastCons
    #	This job is I/O intensive in its output files, beware where this
    #	takes place or do not run too many at once.
    ssh ku
    mkdir -p /hive/data/genomes/wuhCor1/bed/multiz119way/cons/run.cons
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/cons/run.cons

    #	This is setup for multiple runs based on subsets, but only running
    #   the 'all' subset here.
    #   It triggers off of the current working directory
    #	$cwd:t which is the "grp" in this script.  Running:
    #	all and vertebrates

    printf '#!/bin/csh -fe
set PHASTBIN = /cluster/bin/phast.build/cornellCVS/phast.2010-12-30/bin
set c = $1
set d = $2
set f = $3
set len = $4
set cov = $5
set rho = $6
set grp = $cwd:t
set cons = /hive/data/genomes/wuhCor1/bed/multiz119way/cons
set tmp = $cons/tmp/${d}_${c}
mkdir -p $tmp
set ssSrc = $cons/SS/result
set useGrp = "$grp.mod"
if (-s $cons/$grp/$grp.non-inf) then
  ln -s $cons/$grp/$grp.mod $tmp
  ln -s $cons/$grp/$grp.non-inf $tmp
  ln -s $ssSrc/$d/$f $tmp
else
  ln -s $ssSrc/$d/$f $tmp
  ln -s $cons/$grp/$grp.mod $tmp
endif
pushd $tmp > /dev/null
if (-s $grp.non-inf) then
  $PHASTBIN/phastCons $f $useGrp \
    --rho $rho --expected-length $len --target-coverage $cov --quiet \\
    --not-informative `cat $grp.non-inf` \\
    --seqname $c --idpref $c --most-conserved $c.bed --score > $c.pp
else
  $PHASTBIN/phastCons $f $useGrp \\
    --rho $rho --expected-length $len --target-coverage $cov --quiet \\
    --seqname $c --idpref $c --most-conserved $c.bed --score > $c.pp
endif
popd > /dev/null
mkdir -p pp/$d bed/$d
sleep 4
touch pp/$d bed/$d
rm -f pp/$d/$c.pp
rm -f bed/$d/$c.bed
mv $tmp/$c.pp pp/$d
mv $tmp/$c.bed bed/$d
rm -fr $tmp
rmdir --ignore-fail-on-non-empty $cons/tmp/$d:h
' > doPhast.csh

    chmod +x doPhast.csh

    #	this template will serve for all runs
    #	root1 == chrom name, file1 == ss file name without .ss suffix
    printf '#LOOP
../run.cons/doPhast.csh $(root1) $(dir1) $(file1) 45 0.3 0.3 {check out line+ pp/$(dir1)/$(root1).pp}
#ENDLOOP
' > template

    find ../SS/result -type f | sed -e "s#../SS/result/##" > ss.list
    wc -l ss.list
    #	988 ss.list

    # Create parasol batch and run it
    # run for all species
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/cons/all
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/cons/all
    #	Using the .mod tree
    cp -p ../../4d/all.mod ./all.mod

    gensub2 ../run.cons/ss.list single ../run.cons/template jobList
    para -ram=32g create jobList
    para try ... check ...
    para push
# Completed: 988 of 988 jobs
# CPU time in finished jobs:       2515s      41.91m     0.70h    0.03d  0.000 y
# IO & Wait Time:                  6393s     106.56m     1.78h    0.07d  0.000 y
# Average job time:                   9s       0.15m     0.00h    0.00d
# Longest finished job:              30s       0.50m     0.01h    0.00d
# Submission to last job:            51s       0.85m     0.01h    0.00d

    # create Most Conserved track
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/cons/all
    time cut -f1 ../../../../chrom.sizes | while read C
do
    ls -d bed/?/?/${C} 2> /dev/null | while read D
    do
        echo ${D}/${C}*.bed 1>&2
        cat ${D}/${C}*.bed
    done | sort -k1,1 -k2,2n \
    | awk '{printf "%s\t%d\t%d\tlod=%d\t%s\n", "'${C}'", $2, $3, $5, $5;}'
done > tmpMostConserved.bed
    # real    0m32.669s

    time /cluster/bin/scripts/lodToBedScore tmpMostConserved.bed \
         > mostConserved.bed
    # real    0m8.310s

    # -rw-rw-r--  1 51368105 Mar  9 15:30 mostConserved.bed

    # load into database
    ssh hgwdev
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/cons/all
    time hgLoadBed wuhCor1 phastConsElements119way mostConserved.bed
    # Read 1488448 elements of size 5 from mostConserved.bed
    # real    0m8.385s

    # on human we often try for 6% overall cov, and 70% CDS cov
    # most bets are off here for that goal, these alignments are too few
    #	and too far between
    #	--rho 0.3 --expected-length 46 --target-coverage 0.3
    time featureBits wuhCor1 -enrichment refGene:cds phastConsElements119way
# refGene:cds 1.564%, phastConsElements119way 17.638%, both 1.288%,
#      cover 82.38%, enrich 4.67x
#  real    0m9.863s

    # Create merged posterier probability file and wiggle track data files
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/cons/all
    mkdir downloads

    # the third sed fixes the chrom names, removing the partition extensions
    time (find ./pp -type f | sed -e "s#^./##; s#\.# d #g; s#-# m #;" \
	| sort -k1,1 -k3,3n | sed -e "s# d #.#g; s# m #-#g;" | xargs cat \
	| sed -e 's/\.[0-9][0-9]*-[0-9][0-9]* start/ start/' \
        | gzip -c > downloads/phastCons119way.wigFix.gz)
    # real    3m10.237s

# -rw-rw-r-- 1 449679749 Mar  9 15:35 phastCons119way.wigFix.gz


    # check integrity of data with wigToBigWig
    time (zcat downloads/phastCons119way.wigFix.gz \
	| wigToBigWig -verbose=2 stdin /hive/data/genomes/wuhCor1/chrom.sizes \
	    phastCons119way.bw) > bigWig.log 2>&1
    egrep "real|VmPeak" bigWig.log
# pid=62255: VmPeak:     3407948 kB
# real    2m59.768s

    bigWigInfo phastCons119way.bw | sed -e 's/^/# /;'
# version: 4
# isCompressed: yes
# isSwapped: 0
# primaryDataSize: 721,160,862
# primaryIndexSize: 17,722,396
# zoomLevels: 10
# chromCount: 867
# basesCovered: 311,564,898
# mean: 0.714476
# min: 0.000000
# max: 1.000000
# std: 0.348523

    #	encode those files into wiggle data
    time (zcat downloads/phastCons119way.wigFix.gz \
	| wigEncode stdin phastCons119way.wig phastCons119way.wib)
    # Converted stdin, upper limit 1.00, lower limit 0.00
    #  real    1m16.871s


    du -hsc *.wi?
    # 298M    phastCons119way.wib
    #  53M     phastCons119way.wig

    # Load gbdb and database with wiggle.
    ln -s `pwd`/phastCons119way.wib /gbdb/wuhCor1/multiz119way/phastCons119way.wib
    time hgLoadWiggle -pathPrefix=/gbdb/wuhCor1/multiz119way \
	wuhCor1 phastCons119way phastCons119way.wig
    #   real    0m3.628s

    # use to set trackDb.ra entries for wiggle min and max
    # and verify table is loaded correctly

    wigTableStats.sh wuhCor1 phastCons119way
# db.table               min max mean       count sumData
# wuhCor1.phastCons119way 0 1 0.714476 311564898 2.22606e+08
#     stdDev  viewLimits
#    0.348523 viewLimits=0:1

    #  Create histogram to get an overview of all the data
    #  Do not mix stderr with the output, it gets confused
    time hgWiggle -doHistogram -db=wuhCor1 \
	-hBinSize=0.001 -hBinCount=1000 -hMinVal=0.0 -verbose=2 \
	    phastCons119way > wuhCor1.phastCons119way.histogram.data 2> t.err
XXX - running - Mon Mar  9 15:47:59 PDT 2020
    #	real    1m15.914s

    # the Y axis range:
    grep -v "^#" wuhCor1.phastCons119way.histogram.data | awk '{print $5}'  | ave stdin
# Q1 0.000107
# median 0.000218
# Q3 0.000547
# average 0.001000
# min 0.000012
# max 0.240878
# count 1000
# total 1.000008
# standard deviation 0.007900

    #	create plot of histogram:

    # updated for new gnuplot on hgwdev 2018-11-26 (can't get font to change)
    printf 'set terminal pngcairo size 1000,600 background "#000000" font "/usr/share/fonts/default/Type1/n022004l.pfb"
set output "wuhCor1.phastCons119way.histo.png"
set size 1.0, 1.0
set style line 1 lt 2 lc rgb "#ff88ff" lw 2
set style line 2 lt 2 lc rgb "#66ff66" lw 2
set style line 3 lt 2 lc rgb "#ffff00" lw 2
set style line 4 lt 2 lc rgb "#ffffff" lw 2
set border lc rgb "#ffff00"
set key left box ls 3
set key tc variable
set grid noxtics
set y2tics
set grid ytics ls 4
set title " Rat/wuhCor1 Histogram phastCons119way track" \
    tc rgb "#ffffff"
set xlabel " phastCons119way score" tc rgb "#ffffff"
set ylabel " Relative Frequency" tc rgb "#ff88ff"
set y2label " Cumulative Relative Frequency (CRF)" tc rgb "#66ff66"
set y2range [0:1]
set yrange [0:0.25]

plot "wuhCor1.phastCons119way.histogram.data" using 2:5 title " RelFreq" with impulses ls 1, \
        "wuhCor1.phastCons119way.histogram.data" using 2:7 axes x1y2 title " CRF" with lines ls 2
' | gnuplot

    display wuhCor1.phastCons119way.histo.png &

#########################################################################
# phyloP for 119way (TBD - 2016-06-09,11 - Hiram)
    # run phyloP with score=LRT
    ssh ku
    mkdir /cluster/data/wuhCor1/bed/multiz119way/consPhyloP
    cd /cluster/data/wuhCor1/bed/multiz119way/consPhyloP

    mkdir run.phyloP
    cd run.phyloP
    # Adjust model file base composition background and rate matrix to be
    # representative of the chromosomes in play
    grep BACKGROUND ../../4d/all.mod | awk '{printf "%0.3f\n", $3 + $4}'
    #	0.584
    /cluster/bin/phast.build/cornellCVS/phast.2010-12-30/bin/modFreqs \
	../../4d/all.mod 0.584 > all.mod
    # verify, the BACKGROUND should now be paired up:
    grep BACK all.mod
    #   BACKGROUND: 0.208000 0.292000 0.292000 0.208000 

    printf '#!/bin/csh -fe
set PHASTBIN = /cluster/bin/phast.build/cornellCVS/phast.2010-12-30/bin
set f = $1
set d = $f:h
set file1 = $f:t
set out = $2
set cName = $f:t:r
set grp = $cwd:t
set cons = /hive/data/genomes/wuhCor1/bed/multiz119way/consPhyloP
set tmp = $cons/tmp/$grp/$f
/bin/rm -fr $tmp
/bin/mkdir -p $tmp
set ssSrc = "/hive/data/genomes/wuhCor1/bed/multiz119way/cons/SS/result/$f"
set useGrp = "$grp.mod"
/bin/ln -s $cons/run.phyloP/$grp.mod $tmp
pushd $tmp > /dev/null
$PHASTBIN/phyloP --method LRT --mode CONACC --wig-scores --chrom $cName \\
    -i SS $useGrp $ssSrc.ss > $file1.wigFix
popd > /dev/null
/bin/mkdir -p $out:h
sleep 4
/bin/touch $out:h
/bin/mv $tmp/$file1.wigFix $out
/bin/rm -fr $tmp
/bin/rmdir --ignore-fail-on-non-empty $cons/tmp/$grp/$d
/bin/rmdir --ignore-fail-on-non-empty $cons/tmp/$grp/$d:h
/bin/rmdir --ignore-fail-on-non-empty $cons/tmp/$grp
/bin/rmdir --ignore-fail-on-non-empty $cons/tmp
' > doPhyloP.csh

    chmod +x doPhyloP.csh

    # Create list of chunks
    find ../../cons/SS/result -type f | grep ".ss$" \
	| sed -e "s/.ss$//; s#^../../cons/SS/result/##" > ss.list
    # make sure the list looks good
    wc -l ss.list
    #	252 ss.list

    # Create template file
    #	file1 == $chr/$chunk/file name without .ss suffix
    printf '#LOOP
../run.phyloP/doPhyloP.csh $(path1) {check out line+ wigFix/$(dir1)/$(file1).wigFix}
#ENDLOOP
' > template

    ######################   Running all species  #######################
    # setup run for all species
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/consPhyloP/all
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/consPhyloP/all
    rm -fr wigFix
    mkdir wigFix

    gensub2 ../run.phyloP/ss.list single ../run.phyloP/template jobList
    #	beware overwhelming the cluster with these fast running high I/O jobs
    para create jobList
    para try ... check ... push ... etc ...
    para -maxJob=63 push
    para time > run.time
# Completed: 252 of 252 jobs
# CPU time in finished jobs:       4205s      70.08m     1.17h    0.05d  0.000 y
# IO & Wait Time:                  1675s      27.92m     0.47h    0.02d  0.000 y
# Average job time:                  23s       0.39m     0.01h    0.00d
# Longest finished job:              31s       0.52m     0.01h    0.00d
# Submission to last job:           240s       4.00m     0.07h    0.00d

    mkdir downloads

    time (find ./wigFix -type f | sed -e "s#^./##; s#\.# d #g; s#-# m #;" \
	| sort -k1,1 -k3,3n | sed -e "s# d #.#g; s# m #-#g;" | xargs cat \
	| gzip -c > downloads/phyloP119way.wigFix.gz)
    #   real    14m25.749s
    # check integrity of data with wigToBigWig
    time (zcat downloads/phyloP119way.wigFix.gz \
	| wigToBigWig -verbose=2 stdin /hive/data/genomes/wuhCor1/chrom.sizes \
	phyloP119way.bw) > bigWig.log 2>&1
    egrep "real|VmPeak" bigWig.log
# pid=45264: VmPeak:    18745464 kB
# real    17m48.730s

    bigWigInfo phyloP119way.bw | sed -e 's/^/# /;'
# version: 4
# isCompressed: yes
# isSwapped: 0
# primaryDataSize: 2,570,662,548
# primaryIndexSize: 62,912,880
# zoomLevels: 10
# chromCount: 22
# basesCovered: 1,694,662,819
# mean: 0.082710
# min: -4.373000
# max: 0.967000
# std: 0.593297

    #	encode those files into wiggle data
    time (zcat downloads/phyloP119way.wigFix.gz \
	| wigEncode stdin phyloP119way.wig phyloP119way.wib)
    # Converted stdin, upper limit 0.97, lower limit -4.37
    # real    7m29.488s

    du -hsc *.wi?
    # 1.6G    phyloP119way.wib
    # 189M    phyloP119way.wig

    # Load gbdb and database with wiggle.
    ln -s `pwd`/phyloP119way.wib /gbdb/wuhCor1/multiz119way/phyloP119way.wib
    time hgLoadWiggle -pathPrefix=/gbdb/wuhCor1/multiz119way wuhCor1 \
	phyloP119way phyloP119way.wig
    # real    0m12.985s

    # use to set trackDb.ra entries for wiggle min and max
    # and verify table is loaded correctly

    wigTableStats.sh wuhCor1 phyloP119way
# db.table              min max mean count sumData
# wuhCor1.phyloP119way  -4.373 0.967 0.0827105 1694662819 1.40166e+08
#       stdDev viewLimits
#   0.593297 viewLimits=-2.88378:0.967

    #	that range is: 4.373+0.967 = 5.340 for hBinSize=0.00534

    #  Create histogram to get an overview of all the data
    #  do NOT mix up stderr with the output, it interferes with the output
    time (hgWiggle -doHistogram \
	-hBinSize=0.00534 -hBinCount=1000 -hMinVal=-4.373 -verbose=2 \
	    -db=wuhCor1 phyloP119way) > wuhCor1.phyloP119way.histogram.data \
               2> t.err
    # real    1m15.999s

    # find the Y range for the 2:6 graph
    grep "^[0-9]" wuhCor1.phyloP119way.histogram.data | ave -col=5 stdin \
      | sed -e 's/^/# /;'
# Q1 0.000003
# median 0.000044
# Q3 0.000888
# average 0.001037
# min 0.000000
# max 0.059670
# count 964
# total 0.999981
# standard deviation 0.003914

    # find the X range for the 2:6 graph
    grep "^[0-9]" wuhCor1.phyloP119way.histogram.data | ave -col=2 stdin \
      | sed -e 's/^/# /;'
# Q1 -3.088730
# median -1.801790
# Q3 -0.514850
# average -1.778824
# min -4.373000
# max 0.967000
# count 964
# total -1714.785920
# standard deviation 1.522294

    #	create plot of histogram:
    # updated for new gnuplot on hgwdev 2018-11-26 (can't get font to change)
    printf 'set terminal pngcairo size 1000,600 background "#000000" font "/usr/share/fonts/default/Type1/n022004l.pfb"
set output "wuhCor1.phyloP119way.histo.png"
set size 1.0, 1.0
set style line 1 lt 2 lc rgb "#ff88ff" lw 2
set style line 2 lt 2 lc rgb "#66ff66" lw 2
set style line 3 lt 2 lc rgb "#ffff00" lw 2
set style line 4 lt 2 lc rgb "#ffffff" lw 2
set border lc rgb "#ffff00"
set key left box ls 3
set key tc variable
set grid noxtics
set y2tics
set grid ytics ls 4
set title " Rat/wuhCor1 Histogram phyloP119way track" \
    tc rgb "#ffffff"
set xlabel " phyloP119way score" tc rgb "#ffffff"
set ylabel " Relative Frequency" tc rgb "#ff88ff"
set y2label " Cumulative Relative Frequency (CRF)" tc rgb "#66ff66"
set y2range [0:1]
set xrange [-4.4:0.97]
set yrange [0:0.06]

plot "wuhCor1.phyloP119way.histogram.data" using 2:5 title " RelFreq" with impulses ls 1, \
        "wuhCor1.phyloP119way.histogram.data" using 2:7 axes x1y2 title " CRF" with lines ls 2
' | gnuplot

# set xrange [-4.4:0.97]

    display wuhCor1.phyloP119way.histo.png &

    # appears to have an odd hole in the data near X=0 ?

#############################################################################
# hgPal downloads (TBD - 2016-06-09,11 - Hiram)
#   FASTA from 119way for refGene

    ssh hgwdev
    screen -S wuhCor1HgPal
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/pal
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/pal
    cat ../species.list | tr '[ ]' '[\n]' > order.list

    # this for loop takes about 2.6 hours on this large count contig assembly
    export mz=multiz119way
    export gp=refGene
    export db=wuhCor1
    export I=0
    export D=0
    mkdir exonAA exonNuc
    printf '#!/bin/sh\n' > $gp.jobs

    time for C in `sort -nk2 ../../../chrom.sizes | cut -f1`
    do
        I=`echo $I | awk '{print $1+1}'`
        D=`echo $D | awk '{print $1+1}'`
        dNum=`echo $D | awk '{printf "%03d", int($1/1000)}'`
        mkdir -p exonNuc/${dNum} > /dev/null
        mkdir -p exonAA/${dNum} > /dev/null
	echo "mafGene -chrom=$C -exons -noTrans $db $mz $gp order.list stdout | gzip -c > exonNuc/${dNum}/$C.exonNuc.fa.gz &"
	echo "mafGene -chrom=$C -exons $db $mz $gp order.list stdout | gzip -c > exonAA/${dNum}/$C.exonAA.fa.gz &"
        if [ $I -gt 16 ]; then
            echo "date"
            echo "wait"
            I=0
        fi
    done >> $gp.jobs
    # real    0m0.680s

    echo "date" >> $gp.jobs
    echo "wait" >> $gp.jobs

    chmod +x  $gp.jobs 

    time (./$gp.jobs) > $gp.jobs.log 2>&1 &
    # real    2m39.932s

    export mz=multiz119way
    export gp=refGene
    time find ./exonAA -type f | grep exonAA.fa.gz | xargs zcat \
     | gzip -c > $gp.$mz.exonAA.fa.gz
    #  real    0m5.683s

    time find ./exonNuc -type f | grep exonNuc.fa.gz | xargs zcat \
     | gzip -c > $gp.$mz.exonNuc.fa.gz
    #  real    0m24.455s

# -rw-rw-r-- 1 28108399 Oct 17 10:54 refGene.multiz119way.exonAA.fa.gz
# -rw-rw-r-- 1 46239299 Oct 17 10:54 refGene.multiz119way.exonNuc.fa.gz

    export mz=multiz119way
    export gp=refGene
    export db=wuhCor1
    export pd=/usr/local/apache/htdocs-hgdownload/goldenPath/$db/$mz/alignments
    mkdir -p $pd
    md5sum *.fa.gz > md5sum.txt
    ln -s `pwd`/$gp.$mz.exonAA.fa.gz $pd/$gp.exonAA.fa.gz
    ln -s `pwd`/$gp.$mz.exonNuc.fa.gz $pd/$gp.exonNuc.fa.gz
    ln -s `pwd`/md5sum.txt $pd/

    rm -rf exonAA exonNuc

#############################################################################
XXX - ready to go - Thu Oct 17 10:57:20 PDT 2019
# construct download files for 119way (TBD - 2016-06-11 - Hiram)
    mkdir /usr/local/apache/htdocs-hgdownload/goldenPath/wuhCor1/multiz119way
    mkdir /usr/local/apache/htdocs-hgdownload/goldenPath/wuhCor1/phastCons119way
    mkdir /usr/local/apache/htdocs-hgdownload/goldenPath/wuhCor1/phyloP119way
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/downloads
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/downloads
    mkdir multiz119way phastCons119way phyloP119way
    cd multiz119way
    time cp -p ../../anno/wuhCor1.119way.maf .
    #   real    0m23.199s

    # -rw-rw-r-- 1 12551361334 Oct 16 10:13 wuhCor1.119way.maf

    du -hsc *
    #  12G     wuhCor1.119way.maf

    time gzip *.maf
    #   real    43m18.329s
    # real    22m31.598s

    # -rw-rw-r-- 1 3005396685 Oct 16 10:13 wuhCor1.119way.maf.gz

    du -hsc *.maf.gz ../../anno/*.maf
# 2.8G    wuhCor1.119way.maf.gz
# 12G     ../../anno/wuhCor1.119way.maf

    grep TREE ../../4d/all.mod | awk '{print $NF}' \
      | ~/kent/src/hg/utils/phyloTrees/asciiTree.pl /dev/stdin \
         > wuhCor1.119way.nh
    ln -s ../../wuhCor1.119way.commonNames.nh .
    ln -s ../../wuhCor1.119way.scientificNames.nh
    time md5sum *.nh *.maf.gz > md5sum.txt
    #   real    0m36.144s

    ln -s `pwd`/* \
        /usr/local/apache/htdocs-hgdownload/goldenPath/wuhCor1/multiz119way

    du -hsc *.maf.gz ../../anno/wuhCor1.119way.maf
    #  3.0G     wuhCor1.119way.maf.gz
    #  13G     ../../anno/wuhCor1.119way.maf

    # obtain the README.txt from galGal7/multiz7119way and update for this
    #   situation

    # to get the species table list for the README:
    for F in `cat ../../species.list`
do
      hgsql -N -e "select organism,scientificName,description from dbDb where name=\"$F\";" hgcentraltest
done | cat

Rat     Rattus norvegicus       May. 2019 (Regen Rn1/wuhCor1)
Mouse   Mus musculus    Dec. 2011 (GRCm38/mm10)
Rabbit  Oryctolagus cuniculus   Apr. 2009 (Broad/oryCun2)
Human   Homo sapiens    Dec. 2013 (GRCh38/hg38)
Crab-eating macaque     Macaca fascicularis     Jun. 2013 (Macaca_fascicularis_5.0/macFas5)
Pig     Sus scrofa      Feb. 2017 (Sscrofa11.1/susScr11)
Dog     Canis lupus familiaris  Sep. 2011 (Broad CanFam3.1/canFam3)

    #####################################################################
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/downloads/phastCons119way

    ln -s ../../cons/all/downloads/phastCons119way.wigFix.gz \
        ./wuhCor1.phastCons119way.wigFix.gz
    ln -s ../../cons/all/phastCons119way.bw ./wuhCor1.phastCons119way.bw
    ln -s ../../cons/all/all.mod ./wuhCor1.phastCons119way.mod
    time md5sum *.gz *.mod *.bw > md5sum.txt
    #   real    0m15.741s

    # obtain the README.txt from galGal6/phastCons7119way and update for this

    #   situation
    ln -s `pwd`/* \
      /usr/local/apache/htdocs-hgdownload/goldenPath/wuhCor1/phastCons119way

    #####################################################################
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/downloads/phyloP119way

    ln -s ../../consPhyloP/all/downloads/phyloP119way.wigFix.gz \
        ./wuhCor1.phyloP119way.wigFix.gz
    ln -s ../../consPhyloP/run.phyloP/all.mod wuhCor1.phyloP119way.mod
    ln -s ../../consPhyloP/all/phyloP119way.bw wuhCor1.phyloP119way.bw

    time md5sum *.mod *.bw *.gz > md5sum.txt
    #   real    0m18.237s

    # obtain the README.txt from galGal6/phyloP7119way and update for this
    #   situation
    ln -s `pwd`/* \
      /usr/local/apache/htdocs-hgdownload/goldenPath/wuhCor1/phyloP119way

    ###########################################################################
    ## create upstream refGene maf files
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/downloads/multiz119way
    # bash script
#!/bin/sh
export geneTbl="refGene"
for S in 1000 2000 5000
do
    echo "making upstream${S}.maf"
    featureBits wuhCor1 ${geneTbl}:upstream:${S} -fa=/dev/null -bed=stdout \
        | perl -wpe 's/_up[^\t]+/\t0/' | sort -k1,1 -k2,2n \
        | /cluster/bin/$MACHTYPE/mafFrags wuhCor1 multiz119way \
                stdin stdout \
                -orgs=/hive/data/genomes/wuhCor1/bed/multiz119way/species.list \
        | gzip -c > upstream${S}.${geneTbl}.maf.gz
    echo "done upstream${S}.${geneTbl}.maf.gz"
done
XXX - running - Thu Oct 17 15:09:16 PDT 2019
    #   about 10 minutes

    md5sum *.maf.gz *.nh upstream*.gz README.txt >> md5sum.txt

    # some other symlinks were already made above
    # obtain the README.txt from cavPor3/multiz119way and update for this
    #   situation
    ln -s `pwd`/upstream*.gz `pwd`/README.txt \
        /usr/local/apache/htdocs-hgdownload/goldenPath/wuhCor1/multiz119way

#############################################################################
# hgPal downloads (TBD - 2016-06-11 - Hiram)
#   FASTA from 119way for knownGene, refGene and knownCanonical

    ssh hgwdev
    screen -S wuhCor1HgPal
    mkdir /hive/data/genomes/wuhCor1/bed/multiz119way/pal
    cd /hive/data/genomes/wuhCor1/bed/multiz119way/pal
    cat ../species.list | tr '[ ]' '[\n]' > order.list

    # this for loop takes about 2.6 hours on this large count contig assembly
    export mz=multiz119way
    export gp=refGene
    export db=wuhCor1
    export I=0
    export D=0
    mkdir exonAA exonNuc
    for C in `sort -nk2 ../../../chrom.sizes | cut -f1`
    do
        I=`echo $I | awk '{print $1+1}'`
        D=`echo $D | awk '{print $1+1}'`
        dNum=`echo $D | awk '{printf "%03d", int($1/1000)}'`
        mkdir -p exonNuc/${dNum} > /dev/null
        mkdir -p exonAA/${dNum} > /dev/null
	echo "mafGene -chrom=$C -exons -noTrans $db $mz $gp order.list stdout | gzip -c > exonNuc/${dNum}/$C.exonNuc.fa.gz &"
	echo "mafGene -chrom=$C -exons $db $mz $gp order.list stdout | gzip -c > exonAA/${dNum}/$C.exonAA.fa.gz &"
        if [ $I -gt 16 ]; then
            echo "date"
            echo "wait"
            I=0
        fi
    done > $gp.jobs
    echo "date" >> $gp.jobs
    echo "wait" >> $gp.jobs

    time sh -x ./$gp.jobs > $gp.jobs.log 2>&1 &
    # real    176m60.376s


    export mz=multiz119way
    export gp=refGene
    time find ./exonAA -type f | grep exonAA.fa.gz | xargs zcat \
     | gzip -c > $gp.$mz.exonAA.fa.gz
    # real    10m29.600s

    time find ./exonNuc -type f | grep exonNuc.fa.gz | xargs zcat \
     | gzip -c > $gp.$mz.exonNuc.fa.gz
    #   real    16m9.974s

  # -rw-rw-r--   1 611281644 Apr 16 20:37 refGene.multiz119way.exonAA.fa.gz
  # -rw-rw-r--   1 966671426 Apr 16 21:06 refGene.multiz119way.exonNuc.fa.gz

    export mz=multiz119way
    export gp=refGene
    export db=wuhCor1
    export pd=/usr/local/apache/htdocs-hgdownload/goldenPath/$db/$mz/alignments
    mkdir -p $pd
    md5sum *.fa.gz > md5sum.txt
    ln -s `pwd`/$gp.$mz.exonAA.fa.gz $pd/$gp.exonAA.fa.gz
    ln -s `pwd`/$gp.$mz.exonNuc.fa.gz $pd/$gp.exonNuc.fa.gz
    ln -s `pwd`/md5sum.txt $pd/

    rm -rf exonAA exonNuc

#############################################################################
# wiki page for 119way (DONE - 2017-12-18 - Hiram)
    mkdir /hive/users/hiram/bigWays/wuhCor1.119way
    cd /hive/users/hiram/bigWays
    echo "wuhCor1" > wuhCor1.119way/ordered.list
    awk '{print $1}' /hive/data/genomes/wuhCor1/bed/multiz119way/119way.distances.txt \
       >> wuhCor1.119way/ordered.list

    # sizeStats.sh catches up the cached measurements required for data
    # in the tables.  They are usually already mostly done, only new
    # assemblies will have updates.
    ./sizeStats.sh wuhCor1.119way/ordered.list
    # dbDb.sh constructs wuhCor1.119way/GalVar1_119way_conservation_alignment.html
    # may need to add new assembly references to srcReference.list and
    # urlReference.list
    ./dbDb.sh wuhCor1 119way
    # sizeStats.pl constructs wuhCor1.119way/GalVar1_119way_Genome_size_statistics.html
    # this requires entries in coverage.list for new sequences
    ./sizeStats.pl wuhCor1 119way

    # defCheck.pl constructs GalVar1_119way_conservation_lastz_parameters.html
    ./defCheck.pl wuhCor1 119way

    # this constructs the html pages in wuhCor1.119way/:
# -rw-rw-r--    3848 Dec 18 14:05 GalVar1_119way_conservation_alignment.html
# -rw-rw-r--    5500 Dec 18 14:05 GalVar1_119way_Genome_size_statistics.html
# -rw-rw-r--    3613 Dec 18 14:05 GalVar1_119way_conservation_lastz_parameters.html

    # add those pages to the genomewiki.  Their page names are the
    # names of the .html files without the .html:
#  GalVar1_119way_conservation_alignment
#  GalVar1_6way_Genome_size_statistics
#  GalVar1_6way_conservation_lastz_parameters

    # when you view the first one you enter, it will have links to the
    # missing two.

############################################################################
